{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### КР2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Бустинг. - 6 баллов\n",
    "В существующий код бустинга добавьте возможность ранней остановки обучения. \n",
    "должны быть учтены:\n",
    "1) Наличие валидационного датасета (либо разделение должно быть внутри класса, либо вне его, а в обучении новый набор будет подаваться отдельной парой)\n",
    "2) Кастомная метрика или лосс для оствновки. Должна передаваться в виде доп. параметра. Дефолт - лосс функция для расчета градиента.\n",
    "3) Укажите, сколько должно пройти итераций для ранней остановки. \n",
    "4) После обучения должно вернуться лучшее состояние модели по валидационной выборке, а не то, которое было достинуто при остановке обучения. \n",
    "\n",
    "Для обучения используйте тот же датасет, что использовался на 8 семинаре (house_price_regression_dataset).\n",
    "1 и 3 пункты обязательны - 3 балла. 2 пункт - 1 балл (при недефолтной реализации). 4 пункт - 2 балла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "### Собственная реализация\n",
    "class MyGradientRegressor:\n",
    "    def __init__(self, n_estimators: int = 300, max_depth: int = 3, lr: float = 0.1):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.lr = lr\n",
    "        self.estimators = []\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "\n",
    "        self.estimators = []\n",
    "        predictions = 0\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            new_model = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            new_target = -2 * (predictions - y_train)\n",
    "            new_model.fit(X_train, new_target)\n",
    "            predictions += self.lr * new_model.predict(X_train)\n",
    "            self.estimators.append(new_model)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_test = np.array(X_test)\n",
    "        curr_pred = 0\n",
    "        for est in self.estimators:\n",
    "            curr_pred += self.lr * est.predict(X_test)\n",
    "\n",
    "        return curr_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение задания \"Бустинг\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class MyGradientRegressor:\n",
    "    def __init__(self, n_estimators=300, max_depth=3, early_stop_rounds=10, eval_metric=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.early_stop_rounds = early_stop_rounds\n",
    "        self.eval_metric = eval_metric if eval_metric else mean_squared_error\n",
    "        self.estimators = []\n",
    "        self.best_estimators = []\n",
    "\n",
    "    def fit(self, X_train, y_train, X_valid, y_valid):\n",
    "        self.estimators = []\n",
    "        best_score = np.inf\n",
    "        no_improve_count = 0\n",
    "        preds = np.zeros(X_train.shape[0])\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            model = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            gradient = y_train - preds\n",
    "            model.fit(X_train, gradient)\n",
    "\n",
    "            preds += model.predict(X_train)\n",
    "            self.estimators.append(model)\n",
    "\n",
    "            # Проверка\n",
    "            pred_valid = self.predict(X_valid)\n",
    "            valid_score = self.eval_metric(y_valid, pred_valid)\n",
    "\n",
    "            if valid_score < best_score:\n",
    "                best_score = valid_score\n",
    "                no_improve_count = 0\n",
    "                self.best_estimators = self.estimators.copy()\n",
    "            else:\n",
    "                no_improve_count += 1\n",
    "\n",
    "            if no_improve_count >= self.early_stop_rounds:\n",
    "                print(f\"Ранняя остановка после {i+1} итераций\")\n",
    "                break\n",
    "\n",
    "        self.estimators = self.best_estimators.copy()\n",
    "\n",
    "    def predict(self, X):\n",
    "        preds_sum = np.zeros(X.shape[0])\n",
    "        for tree in self.estimators:\n",
    "            preds_sum += tree.predict(X)\n",
    "        return preds_sum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранняя остановка после 33 итераций\n",
      "MSE на валидации после ранней остановки: 402124171.7\n",
      "MSE на тестовом наборе: 509017399.8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dom_df = pd.read_csv('house_price_regression_dataset.csv')\n",
    "\n",
    "X_dom = dom_df.drop('House_Price', axis=1)\n",
    "y_cena = dom_df['House_Price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_dom, y_cena, test_size=0.2, random_state=42)\n",
    "\n",
    "# Нормировка\n",
    "norma = StandardScaler()\n",
    "X_train_norm = norma.fit_transform(X_train)\n",
    "X_test_norm = norma.transform(X_test)\n",
    "\n",
    "# Валидационный сплит (для ранней остановки)\n",
    "X_train_osn, X_valid, y_train_osn, y_valid = train_test_split(X_train_norm, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обучение модели с ранней остановкой\n",
    "boost_modelka = MyGradientRegressor(n_estimators=100, max_depth=3, early_stop_rounds=5)\n",
    "boost_modelka.fit(X_train_osn, y_train_osn, X_valid, y_valid)\n",
    "\n",
    "# Проверка\n",
    "pred_valid = boost_modelka.predict(X_valid)\n",
    "mse_valid = mean_squared_error(y_valid, pred_valid)\n",
    "print(f\"MSE на валидации после ранней остановки: {mse_valid:.1f}\")\n",
    "\n",
    "pred_test = boost_modelka.predict(X_test_norm)\n",
    "mse_test = mean_squared_error(y_test, pred_test)\n",
    "print(f\"MSE на тестовом наборе: {mse_test:.1f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стекинг - 4 балла\n",
    "В текущей реализации в качестве признаков для метамодели используются предсказания базовых моделей.\n",
    "Ваша задача добавить возможность дополнительно учитывать исходные данные в качестве признаков (гиперпараметр). \n",
    "Метапризнаки как доп. фичи к основным.\n",
    "При этом на основные признаки добавляется воможность расчета полиномиальных признаков (https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)\n",
    "\n",
    "Для тестирования используйте тот же датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "class Stacking:\n",
    "    def __init__(self, estimators, meta_estimator, folds=5):\n",
    "        self.estimators = estimators\n",
    "        self.meta_estimator = meta_estimator\n",
    "        self.folds = folds\n",
    "        self.meta_train = []\n",
    "\n",
    "    def _fit_estimator(self, estimator, X_train, y_train):\n",
    "        kf = KFold(n_splits=self.folds, shuffle=True)\n",
    "        train_fold_indices = []\n",
    "        test_fold_indices = []\n",
    "        test_fold_predicts = []\n",
    "\n",
    "        for train_idx, test_idx in kf.split(X_train):\n",
    "            train_fold_indices.extend(train_idx)\n",
    "            test_fold_indices.extend(test_idx)\n",
    "\n",
    "            estimator.fit(X_train[train_idx], y_train[train_idx])\n",
    "            test_fold_predicts.extend(estimator.predict(X_train[test_idx]))\n",
    "\n",
    "        estimator.fit(X_train, y_train)\n",
    "        self.meta_train.append(np.array(test_fold_predicts)[np.argsort(test_fold_indices)])\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "        self.meta_train = []\n",
    "\n",
    "        for estimator in self.estimators:\n",
    "            self._fit_estimator(estimator, X_train, y_train)\n",
    "\n",
    "        self.meta_train = np.array(self.meta_train).transpose()\n",
    "        self.meta_estimator.fit(self.meta_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_test = np.array(X_test)\n",
    "        meta_features = np.array([estimator.predict(X_test) for estimator in self.estimators]).transpose()\n",
    "        return self.meta_estimator.predict(meta_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "class Stacking:\n",
    "    def __init__(self, estimators, meta_estimator, folds=5, use_original_features=False, poly_degree=2):\n",
    "        self.estimators = estimators\n",
    "        self.meta_estimator = meta_estimator\n",
    "        self.folds = folds\n",
    "        self.use_original_features = use_original_features\n",
    "        self.poly_degree = poly_degree\n",
    "        self.poly = None\n",
    "\n",
    "    def _fit_estimator(self, estimator, X, y):\n",
    "        kf = KFold(n_splits=self.folds, shuffle=True, random_state=42)\n",
    "        preds = np.zeros(X.shape[0])\n",
    "\n",
    "        for train_idx, test_idx in kf.split(X):\n",
    "            estimator.fit(X[train_idx], y[train_idx])\n",
    "            preds[test_idx] = estimator.predict(X[test_idx])\n",
    "\n",
    "        estimator.fit(X, y)\n",
    "        return preds\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        meta_features = []\n",
    "        for estimator in self.estimators:\n",
    "            preds = self._fit_estimator(estimator, X_train, y_train)\n",
    "            meta_features.append(preds)\n",
    "\n",
    "        meta_features = np.array(meta_features).T\n",
    "\n",
    "        if self.use_original_features:\n",
    "            self.poly = PolynomialFeatures(degree=self.poly_degree, include_bias=False)\n",
    "            original_poly = self.poly.fit_transform(X_train)\n",
    "            meta_features = np.hstack([meta_features, original_poly])\n",
    "\n",
    "        self.meta_estimator.fit(meta_features, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        meta_features = []\n",
    "        for estimator in self.estimators:\n",
    "            preds = estimator.predict(X_test)\n",
    "            meta_features.append(preds)\n",
    "\n",
    "        meta_features = np.array(meta_features).T\n",
    "\n",
    "        if self.use_original_features and self.poly is not None:\n",
    "            original_poly = self.poly.transform(X_test)\n",
    "            meta_features = np.hstack([meta_features, original_poly])\n",
    "\n",
    "        return self.meta_estimator.predict(meta_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE на тестовом наборе: 103526070.2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "dom_df = pd.read_csv('house_price_regression_dataset.csv')\n",
    "X = dom_df.drop('House_Price', axis=1).values  # класс ест numpy array\n",
    "y = dom_df['House_Price'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "base_estimators = [\n",
    "    DecisionTreeRegressor(max_depth=4, random_state=42),\n",
    "    DecisionTreeRegressor(max_depth=5, random_state=42)\n",
    "]\n",
    "\n",
    "meta_estimator = LinearRegression()\n",
    "\n",
    "stacking_model = Stacking(\n",
    "    estimators=base_estimators,\n",
    "    meta_estimator=meta_estimator,\n",
    "    folds=5,\n",
    "    use_original_features=True,\n",
    "    poly_degree=2\n",
    ")\n",
    "\n",
    "# Обучение\n",
    "stacking_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Предсказание и оценка\n",
    "y_pred = stacking_model.predict(X_test_scaled)\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE на тестовом наборе: {mse_test:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
